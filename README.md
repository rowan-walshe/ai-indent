ai-indent
==============================

## Version 1

Version 1 of the model was the first version that I tried out in VSCode using the model to predict indentation of the next line, making use of the ontypeformatting call that's part of the LSP. This "worked", and was right a good percentage of the time, and was responsive (inference time took about 3ms, even running on CPU).

Using this, two areas of potential improvement that we identified were:
- No context after the cursor position. Context which could turn a blind guess into a certainty
- Context gained after typing the next line could be used to re-predict the line with much better accuracy

## Version 2

#### Planned improvements/work
1. Predict next line, and re-predict current line
  - Only re-predict current line if the line has been modified (e.g. formatters which take into account git history)
2. Give the model context before and after the cursor
3. Remove lines that are just whitespace before performing inference
4. Perform simple de-duplication on training data

## Version 3

#### Planned improvements/work

1. Take into account the type and amount of indexation set in the IDE 
   - This should also have a way of saying 'undefined indentation settings'
   - It should also be able to identify files that have different styles, and so the IDE should be ignored
2. To produce training data of mixed indentation styles (e.g. tabs vs spaces), I plan to make use of some Ada formatter...
4. Perform near de-duplication on training data: https://chenghaomou.github.io/posts/20230220150602


## Version X
- Investigate using context from other files in the project. Useful for new/small files
- Figure out what to do with non-standard with UTF-8 characters ðŸ˜­


Project Organization
------------

    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ Makefile           <- Makefile with commands like `make data` or `make train`
    â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
    â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
    â”‚Â Â  â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
    â”‚Â Â  â””â”€â”€ raw            <- The original, immutable data dump.
    â”‚
    â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
    â”‚
    â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    â”‚                         the creator's initials, and a short `-` delimited description, e.g.
    â”‚                         `1.0-jqp-initial-data-exploration`.
    â”‚
    â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
    â”‚
    â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `pip freeze > requirements.txt`
    â”‚
    â””â”€â”€ src                <- Source code for use in this project.
     Â Â  â”œâ”€â”€ __init__.py    <- Makes src a Python module
        â”‚
     Â Â  â”œâ”€â”€ data           <- Scripts to download or generate data
     Â Â  â”‚Â Â  â””â”€â”€ make_dataset.py
        â”‚
     Â Â  â”œâ”€â”€ features       <- Scripts to turn raw data into features for modeling
     Â Â  â”‚Â Â  â””â”€â”€ build_features.py
        â”‚
     Â Â  â”œâ”€â”€ models         <- Scripts to train models and then use trained models to make
        â”‚   â”‚                 predictions
     Â Â  â”‚Â Â  â”œâ”€â”€ predict_model.py
     Â Â  â”‚Â Â  â””â”€â”€ train_model.py
        â”‚
     Â Â  â””â”€â”€ visualization  <- Scripts to create exploratory and results oriented visualizations
     Â Â      â””â”€â”€ visualize.py

--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
