{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import re\n",
    "\n",
    "class Tokenizer:\n",
    "\n",
    "    _WORD = re.compile(r'^\\w*\\b')\n",
    "\n",
    "    _LIBRARY = [' ', '\\n', '-- A comment', '.', 'abort', 'else', 'new', 'return', 'elsif', 'not', 'reverse', 'abstract', 'end', 'null', 'accept', 'entry', 'select', 'access', 'exception', 'of', 'separate', 'aliased', 'exit', 'some', 'all', 'others', 'subtype', 'and', 'for', 'out', 'synchronized', 'array', 'function', 'overriding', 'at', 'tagged', 'generic', 'package', 'task', 'begin', 'goto', 'pragma', 'terminate', 'body', 'private', 'then', 'if', 'procedure', 'type', 'case', 'in', 'protected', 'constant', 'interface', 'until', 'is', 'raise', 'use', 'declare', 'range', 'delay', 'limited', 'record', 'when', 'delta', 'loop', 'rem', 'while', 'digits', 'renames', 'with', 'do', 'mod', 'requeue', 'xor', 'abs', 'or', '=>', '(', ')', \"'\", '>=', '<=', '/=', '>', '<', ':=', '=', '+', '-', '*', '/', '**', '&', ',', ';', ':', '[', ']']\n",
    "    _LIBRARY_REGEX = {' ': re.compile(r'^ '), '\\n': re.compile(r'^\\n'), '-- A comment': re.compile(r'^--.*'), '.': re.compile(r'^\\.'), 'abort': re.compile(r'^\\babort\\b'), 'else': re.compile(r'^\\belse\\b'), 'new': re.compile(r'^\\bnew\\b'), 'return': re.compile(r'^\\breturn\\b'), 'elsif': re.compile(r'^\\belsif\\b'), 'not': re.compile(r'^\\bnot\\b'), 'reverse': re.compile(r'^\\breverse\\b'), 'abstract': re.compile(r'^\\babstract\\b'), 'end': re.compile(r'^\\bend\\b'), 'null': re.compile(r'^\\bnull\\b'), 'accept': re.compile(r'^\\baccept\\b'), 'entry': re.compile(r'^\\bentry\\b'), 'select': re.compile(r'^\\bselect\\b'), 'access': re.compile(r'^\\baccess\\b'), 'exception': re.compile(r'^\\bexception\\b'), 'of': re.compile(r'^\\bof\\b'), 'separate': re.compile(r'^\\bseparate\\b'), 'aliased': re.compile(r'^\\baliased\\b'), 'exit': re.compile(r'^\\bexit\\b'), 'some': re.compile(r'^\\bsome\\b'), 'all': re.compile(r'^\\ball\\b'), 'others': re.compile(r'^\\bothers\\b'), 'subtype': re.compile(r'^\\bsubtype\\b'), 'and': re.compile(r'^\\band\\b'), 'for': re.compile(r'^\\bfor\\b'), 'out': re.compile(r'^\\bout\\b'), 'synchronized': re.compile(r'^\\bsynchronized\\b'), 'array': re.compile(r'^\\barray\\b'), 'function': re.compile(r'^\\bfunction\\b'), 'overriding': re.compile(r'^\\boverriding\\b'), 'at': re.compile(r'^\\bat\\b'), 'tagged': re.compile(r'^\\btagged\\b'), 'generic': re.compile(r'^\\bgeneric\\b'), 'package': re.compile(r'^\\bpackage\\b'), 'task': re.compile(r'^\\btask\\b'), 'begin': re.compile(r'^\\bbegin\\b'), 'goto': re.compile(r'^\\bgoto\\b'), 'pragma': re.compile(r'^\\bpragma\\b'), 'terminate': re.compile(r'^\\bterminate\\b'), 'body': re.compile(r'^\\bbody\\b'), 'private': re.compile(r'^\\bprivate\\b'), 'then': re.compile(r'^\\bthen\\b'), 'if': re.compile(r'^\\bif\\b'), 'procedure': re.compile(r'^\\bprocedure\\b'), 'type': re.compile(r'^\\btype\\b'), 'case': re.compile(r'^\\bcase\\b'), 'in': re.compile(r'^\\bin\\b'), 'protected': re.compile(r'^\\bprotected\\b'), 'constant': re.compile(r'^\\bconstant\\b'), 'interface': re.compile(r'^\\binterface\\b'), 'until': re.compile(r'^\\buntil\\b'), 'is': re.compile(r'^\\bis\\b'), 'raise': re.compile(r'^\\braise\\b'), 'use': re.compile(r'^\\buse\\b'), 'declare': re.compile(r'^\\bdeclare\\b'), 'range': re.compile(r'^\\brange\\b'), 'delay': re.compile(r'^\\bdelay\\b'), 'limited': re.compile(r'^\\blimited\\b'), 'record': re.compile(r'^\\brecord\\b'), 'when': re.compile(r'^\\bwhen\\b'), 'delta': re.compile(r'^\\bdelta\\b'), 'loop': re.compile(r'^\\bloop\\b'), 'rem': re.compile(r'^\\brem\\b'), 'while': re.compile(r'^\\bwhile\\b'), 'digits': re.compile(r'^\\bdigits\\b'), 'renames': re.compile(r'^\\brenames\\b'), 'with': re.compile(r'^\\bwith\\b'), 'do': re.compile(r'^\\bdo\\b'), 'mod': re.compile(r'^\\bmod\\b'), 'requeue': re.compile(r'^\\brequeue\\b'), 'xor': re.compile(r'^\\bxor\\b'), 'abs': re.compile(r'^\\babs\\b'), 'or': re.compile(r'^\\bor\\b'), '=>': re.compile(r'^=>'), '(': re.compile(r'^\\('), ')': re.compile(r'^\\)'), \"'\": re.compile(r\"^'\"), '>=': re.compile(r'^>='), '<=': re.compile(r'^<='), '/=': re.compile(r'^/='), '>': re.compile(r'^>'), '<': re.compile(r'^<'), ':=': re.compile(r'^:='), '=': re.compile(r'^='), '+': re.compile(r'^\\+'), '-': re.compile(r'^-'), '*': re.compile(r'^\\*'), '/': re.compile(r'^/'), '**': re.compile(r'^\\*\\*'), '&': re.compile(r'^&'), ',': re.compile(r'^,'), ';': re.compile(r'^;'), ':': re.compile(r'^:'), '[': re.compile(r'^\\['), ']': re.compile(r'^\\]'),}\n",
    "\n",
    "    _STRING_LIT = 'STRING_LIT'\n",
    "\n",
    "    _LIBRARY = [_STRING_LIT] + _LIBRARY\n",
    "    _LIBRARY_REGEX[_STRING_LIT] = re.compile(r'^\"(\"\"|[^\"\\n])*\"')\n",
    "\n",
    "    _TOKEN_TO_ID = {k: v for v, k in enumerate(_LIBRARY)}\n",
    "    _ID_TO_TOKEN = {v: k for k, v in _TOKEN_TO_ID.items()}\n",
    "\n",
    "    _PAD = len(_LIBRARY)\n",
    "    _UKN1 = _PAD + 1\n",
    "    _UKN2 = _UKN1 + 1\n",
    "    _UKN4 = _UKN2 + 1\n",
    "    _UKN8 = _UKN4 + 1\n",
    "    _UKN16 = _UKN8 + 1\n",
    "    _UKN32 = _UKN16 + 1\n",
    "    _ID_TO_TOKEN[_PAD] = ''\n",
    "    _ID_TO_TOKEN[_UKN1] = '#'\n",
    "    _ID_TO_TOKEN[_UKN2] = '#' * 2\n",
    "    _ID_TO_TOKEN[_UKN4] = '#' * 4\n",
    "    _ID_TO_TOKEN[_UKN8] = '#' * 8\n",
    "    _ID_TO_TOKEN[_UKN16] = '#' * 16\n",
    "    _ID_TO_TOKEN[_UKN32] = '#' * 32\n",
    "    \n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "       pass\n",
    "\n",
    "    def _gen_uknown(self, unknown_count: int) -> List[int]:\n",
    "        token_ids = []\n",
    "        while unknown_count > 0:\n",
    "            if unknown_count >= 32:\n",
    "                unknown_count -= 32\n",
    "                token_ids.append(self._UKN32)\n",
    "            elif unknown_count >= 16:\n",
    "                unknown_count -= 16\n",
    "                token_ids.append(self._UKN16)\n",
    "            elif unknown_count >= 8:\n",
    "                unknown_count -= 8\n",
    "                token_ids.append(self._UKN8)\n",
    "            elif unknown_count >= 4:\n",
    "                unknown_count -= 4\n",
    "                token_ids.append(self._UKN4)\n",
    "            elif unknown_count >= 2:\n",
    "                unknown_count -= 2\n",
    "                token_ids.append(self._UKN2)\n",
    "            else:\n",
    "                unknown_count -= 1\n",
    "                token_ids.append(self._UKN1)\n",
    "        return token_ids\n",
    "\n",
    "    def encode(self, text: str) -> List[int]:\n",
    "        token_ids = []\n",
    "        unknown_count = 0\n",
    "        while text:\n",
    "            for token in self._LIBRARY:\n",
    "                if match := self._LIBRARY_REGEX[token].match(text):\n",
    "                    token_ids.extend(self._gen_uknown(unknown_count))\n",
    "                    unknown_count = 0\n",
    "                    if token == self._STRING_LIT:\n",
    "                        match_length = len(match.group())\n",
    "                        token_ids.extend([self._TOKEN_TO_ID[token]] * match_length)\n",
    "                        text = text[match_length:]\n",
    "                    else:\n",
    "                        text = self._LIBRARY_REGEX[token].sub('', text, count=1)\n",
    "                        token_ids.append(self._TOKEN_TO_ID[token])\n",
    "                    break\n",
    "            else:\n",
    "                word_length = 1\n",
    "                if match := self._WORD.match(text):\n",
    "                    word_length = len(match.group())\n",
    "                unknown_count += word_length\n",
    "                text = text[word_length:]\n",
    "        token_ids.extend(self._gen_uknown(unknown_count))\n",
    "        return token_ids\n",
    "    \n",
    "    def _decode_string_literals(self, token_ids: List[int]) -> List[Union[int, str]]:\n",
    "        result = []\n",
    "        str_char_count = 0\n",
    "        for token_id in token_ids:\n",
    "            if token_id == self._TOKEN_TO_ID[self._STRING_LIT]:\n",
    "                str_char_count += 1\n",
    "            else:\n",
    "                if str_char_count > 0:\n",
    "                    result.append('\"' + self._ID_TO_TOKEN[self._UKN1] * (str_char_count - 2) + '\"')\n",
    "                    str_char_count = 0\n",
    "                result.append(token_id)\n",
    "        else:\n",
    "            if str_char_count > 0:\n",
    "                    result.append('\"' + self._ID_TO_TOKEN[self._UKN1] * (str_char_count - 2) + '\"')\n",
    "                    str_char_count = 0\n",
    "        return result\n",
    "\n",
    "\n",
    "    def decode(self, token_ids: List[int]) -> str:\n",
    "        partial_decode = self._decode_string_literals(token_ids)\n",
    "        text_parts = [self._ID_TO_TOKEN[x] if isinstance(x, int) else x for x in partial_decode]\n",
    "        return ''.join(text_parts)\n",
    "    \n",
    "    def resize(self, token_ids: List[int], max_length: int) -> List[int]:\n",
    "        # If the token_ids are longer than max_length, truncate the start\n",
    "        # If the token_ids are shorter than max_length, pad the start with _PAD\n",
    "        if len(token_ids) > max_length:\n",
    "            return token_ids[-max_length:]\n",
    "        else:\n",
    "            return [self._PAD] * (max_length - len(token_ids)) + token_ids\n",
    "    \n",
    "    @property\n",
    "    def n_vocab(self) -> int:\n",
    "        return len(self._ID_TO_TOKEN) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 22:26:57.228330: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-20 22:26:57.248229: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set a fixed seed for reproducibility, for the random module, numpy, and tensorflow\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Ada_Drivers_Library' already exists and is not an empty directory.\n",
      "fatal: destination path 'gnatstudio' already exists and is not an empty directory.\n",
      "fatal: destination path 'spark2014' already exists and is not an empty directory.\n",
      "fatal: destination path 'ada_language_server' already exists and is not an empty directory.\n",
      "fatal: destination path 'gnat-llvm' already exists and is not an empty directory.\n",
      "fatal: destination path 'libadalang' already exists and is not an empty directory.\n",
      "fatal: destination path 'aws' already exists and is not an empty directory.\n",
      "fatal: destination path 'RecordFlux' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "git_repos = [\n",
    "    \"https://github.com/AdaCore/Ada_Drivers_Library.git\",\n",
    "    \"https://github.com/AdaCore/gnatstudio.git\",\n",
    "    \"https://github.com/AdaCore/spark2014.git\",\n",
    "    \"https://github.com/AdaCore/ada_language_server.git\",\n",
    "    \"https://github.com/AdaCore/gnat-llvm.git\",\n",
    "    \"https://github.com/AdaCore/libadalang.git\",\n",
    "    \"https://github.com/AdaCore/aws.git\",\n",
    "    \"https://github.com/AdaCore/RecordFlux.git\",\n",
    "]\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "for repo in git_repos:\n",
    "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", repo], cwd=DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import math\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def file_hash(file_path: str):\n",
    "    # Calculate the hash of a file\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_hash = hashlib.sha256()\n",
    "        while chunk := f.read(8192):\n",
    "            file_hash.update(chunk)\n",
    "    return file_hash.hexdigest()\n",
    "\n",
    "def is_file_mostly_space_indented(file_path: str):\n",
    "    # Returns True if the file is mostly space indented\n",
    "    # Returns False if the file is mostly tab indented\n",
    "    # Defaults to False if the file is empty\n",
    "    space_indent_count = 0\n",
    "    tab_indent_count = 0\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        file_contents = f.readlines()\n",
    "        for line in file_contents:\n",
    "            whitespace_count = len(line) - len(line.lstrip())\n",
    "            whitespaces = line[:whitespace_count]\n",
    "            space_indent_count += whitespaces.count(\" \")\n",
    "            tab_indent_count += whitespaces.count(\"\\t\")\n",
    "\n",
    "    # In ada, the convention is to use 3 spaces for indentation\n",
    "    space_indent_count = math.ceil(space_indent_count / 3)\n",
    "    return space_indent_count > tab_indent_count or tab_indent_count == 0\n",
    "\n",
    "\n",
    "def get_files_to_process(data_dir: str, skip_non_utf8_files: bool = True):\n",
    "    # returns a list of unique ada files in the data ada_code_bases directory\n",
    "    file_types_to_keep = {\".ads\", \".adb\", \".gpr\"}\n",
    "    hashes = set()\n",
    "    files_to_process = []\n",
    "\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            file_type = os.path.splitext(file)[1]\n",
    "            if file_type in file_types_to_keep:\n",
    "                file_path = os.path.join(root, file)\n",
    "                hash = file_hash(file_path)\n",
    "                if hash not in hashes:\n",
    "                    hashes.add(hash)\n",
    "                    # If the file is not UTF-8, skip it\n",
    "                    if skip_non_utf8_files:\n",
    "                        try:\n",
    "                            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                                f.read()\n",
    "                            # We only want to process files that are mostly space indented\n",
    "                            if not is_file_mostly_space_indented(file_path):\n",
    "                                continue\n",
    "                            files_to_process.append(file_path)\n",
    "                        except UnicodeDecodeError:\n",
    "                            continue\n",
    "                    else:\n",
    "                        files_to_process.append(file_path)\n",
    "    return files_to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def count_leading_spaces(line: str) -> int:\n",
    "    # Returns the number of leading spaces in line\n",
    "    return len(line) - len(line.lstrip())\n",
    "\n",
    "def filter_empty_lines(lines: List[str]) -> List[str]:\n",
    "    # Returns a list of all lines from lines that are not empty\n",
    "    return [line for line in lines if line.strip() != \"\"]\n",
    "\n",
    "unindent = re.compile(r'^\\s*(begin|end);')\n",
    "def is_unexpected_unindent(line: str) -> bool:\n",
    "    return unindent.match(line) is not None\n",
    "\n",
    "\n",
    "def label_data(files_to_process: List[str], lines_to_group: int) -> List[Tuple[str, int]]:\n",
    "    # For every file in files_to_process, read all of the lines from the file, and assign a label to each line, which is the number of spaces at the beginning of the next line\n",
    "    labelled_data = []\n",
    "    for file in files_to_process:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = filter_empty_lines(f.readlines())\n",
    "            lines.append(\"\")\n",
    "            for i in range(len(lines) - lines_to_group):\n",
    "                data = ''.join(lines[i : i + lines_to_group])\n",
    "                next_line = lines[i + lines_to_group]\n",
    "                if is_unexpected_unindent(next_line):\n",
    "                    continue\n",
    "                label = count_leading_spaces(next_line)\n",
    "                labelled_data.append((data, label))\n",
    "    return labelled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that since 0 is an identation too, the actual max is 119\n",
    "INDENTATION_PREDICTION_CATEGORIES = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files to process: 18633\n"
     ]
    }
   ],
   "source": [
    "files_to_process = get_files_to_process(DATA_DIR)\n",
    "print(f\"Number of files to process: {len(files_to_process)}\")\n",
    "\n",
    "\n",
    "labelled_data = label_data(files_to_process, 3)\n",
    "labelled_data = [(data, label) for data, label in labelled_data if label < INDENTATION_PREDICTION_CATEGORIES]\n",
    "\n",
    "enc = Tokenizer()\n",
    "\n",
    "labelled_data = [(enc.encode(data), label) for data, label in labelled_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_length_count = {}\n",
    "\n",
    "for x in labelled_data:\n",
    "    data_length_count[len(x[0])] = data_length_count.get(len(x[0]), 0) + 1\n",
    "\n",
    "# Plot data_length_count. Make the y axis logarithmic\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(data_length_count.keys(), data_length_count.values())\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([37, 2, 38, 1, 102, 101, 4, 102, 101, 1, 56, 2, 13, 1, 102, 101, 4, 102, 101, 96, 2], 0)\n"
     ]
    }
   ],
   "source": [
    "print(labelled_data[0])\n",
    "labelled_data = [(enc.resize(data, 250), tf.keras.utils.to_categorical(label, num_classes=INDENTATION_PREDICTION_CATEGORIES)) for data, label in labelled_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split labelled_data into two lists, X and y\n",
    "X = [data for data, _ in labelled_data]\n",
    "y = [label for _, label in labelled_data]\n",
    "\n",
    "# Convert X to a numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x_value):\n",
    "    return enc.decode(x_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 22:36:38.964830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 22:36:38.965476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 22:36:38.965897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 22:36:39.011870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-20 22:36:39.026970: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 22:36:39.027439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 22:36:39.027844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 22:36:39.112409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 22:36:39.112884: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 22:36:39.113304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 22:36:39.158322: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 250, 64)           6912      \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 250, 1024)        2363392   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 250, 512)         2623488   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 120)               7800      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,674,424\n",
      "Trainable params: 5,674,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 22:36:39.174147: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 22:36:39.174715: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 22:36:39.175114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 22:36:39.246157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 22:36:39.246631: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 22:36:39.247038: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-20 22:36:39.296031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-06-20 22:36:39.310803: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-20 22:36:39.311233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-20 22:36:39.311628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(enc.n_vocab, 64, input_length=250))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)))\n",
    "    model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(INDENTATION_PREDICTION_CATEGORIES, input_shape=(250,), activation=\"softmax\"))\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "    model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/indentation_prediction_v1_100_epoch.ckpt\"\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "    7/56076 [..............................] - ETA: 13:29:32 - loss: 2.7220 - accuracy: 0.3170"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_val, y_val), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9870/9870 [==============================] - 11s 1ms/step - loss: 0.7003 - accuracy: 0.8093\n"
     ]
    }
   ],
   "source": [
    "# model = create_model()\n",
    "# model.load_weights(checkpoint_path)\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "# loss, accuracy = model.evaluate(X_val, y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
